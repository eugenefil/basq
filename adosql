#!/usr/bin/env winpython3

import sys
import csv
import argparse
import datetime

import adodbapi


COLUMN_NAME = 0
COLUMN_TYPE = 1
COLUMN_SCALE = 5

CONN_STR_VFP = u'Provider=VFPOLEDB.1;Data Source={datasource};Mode=Share Deny None;Extended Properties="";User ID="";Mask Password=False;Cache Authentication=False;Encrypt Password=False;Collating Sequence=MACHINE;DSN="";DELETED=True;CODEPAGE=1251;MVCOUNT=16384;ENGINEBEHAVIOR=90;TABLEVALIDATE=3;REFRESH=5;VARCHARMAPPING=False;ANSI=True;REPROCESS=5'

CONN_STR_MSSQL = u'Provider=SQLNCLI10;Server={server};Database={database};{auth}'
CONN_STR_MSSQL_SRVAUTH = u'Uid={user};Pwd={password}'
CONN_STR_MSSQL_WINAUTH = u'Integrated Security=SSPI'


def cvtDate(default_conv):
    """Return datetime.date from COM date.

    Default adodbapi converter converts COM date (which is number of
    days since 1899-12-30) to datetime.datetime. This converter extracts
    date from that datetime.
    """
    def todate(com_date):
        return default_conv(com_date).date()
    return todate


def cvtRTrim(s):
    return s.rstrip(' ')


ADO_INTEGER = adodbapi.apibase.DBAPITypeObject(
    adodbapi.apibase.adoIntegerTypes +
    adodbapi.apibase.adoLongTypes
)

def ado_type_to_general(column_info):
    adotype = column_info[COLUMN_TYPE]
    if adotype == adodbapi.STRING:
        return 'string'
    elif adotype == ADO_INTEGER:
        return 'integer'
    elif adotype == adodbapi.NUMBER:
        return 'number'
    elif adotype == adodbapi.DATETIME:
        return 'date'
    raise TypeError('ADO type %s cannot be converted to general type' % adotype)


def execsql(cursor, cmd, input_rows=None):
    if not input_rows is None:
        cursor.executemany(cmd, input_rows)
    else:
        cursor.execute(cmd)

    # don't return any results if there are no
    if cursor.description is None:
        return None

    columns = []
    for i, desc in enumerate(cursor.description):
        coltype = ado_type_to_general(desc)
        columns.append({'name': desc[COLUMN_NAME], 'type': coltype})

    return cursor, columns


def todate(s):
    return datetime.datetime.strptime(s, '%Y-%m-%d').date()

def type_parsers():
    idfunc = lambda x: x
    return {
        'string': idfunc,
        'number': float,
        # VFP-SPECIFIC: Pass integers to vfp provider as floats! There
        # seems to be a bug in vfp oledb provider which results in
        # integers passed incorrectly. With python adodbapi integers
        # get passed as zeroes. Passing integers in vbscript with
        # ADODB.Command I got: 1130168319 for passed -1, 1130102784
        # for 0, 1130102785 for 1 and so on. In contrast passing
        # integers to Microsoft ACE provider works fine.
        'integer': float,
        'date': todate
    }


def tolist(row, colnames): return row
def todict(row, colnames): return dict(zip(colnames, row))

def rowfunc(paramstyle):
    return {
        'qmark': tolist,
        'named': todict
    }.get(paramstyle, tolist)


def readrows(file, type_parsers, rowfunc=tolist):
    """Parse input tsv rows from file and return rows of values.

    Parse each value in a input row from its string representation via
    corresponding parser from type_parsers. type_parsers is a dict,
    where types are keys and their parsers are values. If column misses
    type, string is assumed.

    Convert row of values to output row format (list or dict) with
    rowfunc.
    """
    reader = csv.reader(file, delimiter='\t')

    header = next(reader)
    header = [
        dict(zip(
            ('name', 'type'),
            # assume string type if missing
            col.split(' ') + ['string']
        ))
        for col in header
    ]

    colparsers = [type_parsers[col['type']] for col in header]
    colnames = [col['name'] for col in header]

    rows = []
    for row in reader:
        # stop reading on empty line
        if row == []:
            break

        rows.append(rowfunc(
            map(lambda f, v: f(v), colparsers, row),
            colnames
        ))
    return rows


def writerows(file, rows, cols, typed_header=False):
    writer = csv.writer(file, delimiter='\t')

    colnamefunc = {
        False: lambda col: col['name'],
        True: lambda col: col['name'] + ' ' + col['type']
    }[typed_header]
    writer.writerow(colnamefunc(c) for c in cols)

    writer.writerows(rows)


def main(connstr, paramstyle=None, typed_header=False):
    conn = adodbapi.connect(connstr)

    # set proper connection-wide db-to-python type conversions
    conn.variantConversions = adodbapi.apibase.variantConversions
    # convert numeric to float
    conn.variantConversions[adodbapi.ado_consts.adNumeric] = (
        adodbapi.apibase.cvtFloat
    )
    # VFP-SPECIFIC: fixed-width char columns in FoxPro are returned
    # with trailing spaces, so right-trimming is necessary
    conn.variantConversions[adodbapi.ado_consts.adChar] = cvtRTrim
    # convert pure date to date, not datetime
    conn.variantConversions[adodbapi.ado_consts.adDBDate] = cvtDate(
        conn.variantConversions[adodbapi.ado_consts.adDBDate]
    )

    cur = conn.cursor()

    if paramstyle:
        cur.paramstyle = paramstyle

    for line in sys.stdin:
        sqlcmd = line.strip()
        if not sqlcmd:
            continue

        input_rows = None
        if paramstyle:
            input_rows = readrows(
                sys.stdin,
                type_parsers(),
                rowfunc(paramstyle)
            )

        results = execsql(cur, sqlcmd, input_rows)
        if results:
            rows, cols = results
            writerows(sys.stdout, rows, cols, typed_header)

    cur.close()
    conn.commit()
    conn.close()


def vfpconnstr(args):
    return CONN_STR_VFP.format(datasource=args.database)


def mssqlconnstr(args):
    auth = CONN_STR_MSSQL_WINAUTH
    if args.user:
        auth = CONN_STR_MSSQL_SRVAUTH.format(
            user=args.user,
            password=args.password
        )
    return CONN_STR_MSSQL.format(
        auth=auth,
        server=args.server,
        database=args.database
    )


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '-paramstyle',
        choices=('qmark', 'named'),
        help='execute parameterized query. Input values are read as tsv that follows right after the line of query on stdin. Param style in query is one of: qmark (e.g. where id = ?) or named (e.g. where id = :id). With latter column id must be in tsv. Default style: qmark'
    )
    parser.add_argument(
        '-typed-header',
        action='store_true',
        help='output typed header. Each column will contain its type delimited from name by space'
    )

    subparsers = parser.add_subparsers(title='commands')

    vfpparser = subparsers.add_parser(
        'vfp',
        help='Visual FoxPro'
    )
    vfpparser.add_argument(
        'database',
        help='path to .dbc database file'
    )
    vfpparser.set_defaults(getconnstr=vfpconnstr)

    mssqlparser = subparsers.add_parser(
        'mssql',
        description='Windows Authentication is used by default',
        help='Microsoft SQL Server'
    )
    mssqlparser.add_argument(
        '-server',
        default='localhost',
        help='server ip/name. Default: localhost',
        metavar='SRV'
    )
    mssqlparser.add_argument(
        '-database',
        default='',
        help='initial database. Default: server settings',
        metavar='DB'
    )
    mssqlparser.add_argument(
        '-user',
        help='user name for SQL Server Authentication'
    )
    mssqlparser.add_argument(
        '-password',
        default='',
        help='password for SQL Server Authentication',
        metavar='PASS'
    )
    mssqlparser.set_defaults(getconnstr=mssqlconnstr)
    
    return parser.parse_args()


def setup():
    # Redefine stdin to not translate newlines. Otherwise when reading
    # csv field containing \r\n on Windows it gets translated to \n,
    # i.e. data gets corrupted. Always use utf-8.
    sys.stdin = open(
        sys.stdin.fileno(),
        mode=sys.stdin.mode,
        encoding='utf-8',
        errors=sys.stdin.errors,
        newline='',
        closefd=False
    )
    # Redefine stdout to not translate newlines. csv module (as per
    # rfc 4180) writes \r\n. Otherwise when on Windows, \n is
    # translated to \r\n, so original \r\n becomes \r\r\n. Always use
    # utf-8.
    sys.stdout = open(
        sys.stdout.fileno(),
        mode=sys.stdout.mode,
        encoding='utf-8',
        errors=sys.stdout.errors,
        newline='',
        closefd=False
    )


if __name__ == '__main__':
    args = parse_args()
    setup()
    main(
        args.getconnstr(args),
        paramstyle=args.paramstyle,
        typed_header=args.typed_header
    )
